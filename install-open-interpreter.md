In order to access ChatGPT locally, you can install `open-interpreter` using conda. 


**Note : For this aim you should have Open-AI pro account so that you can use GPT4. In my case I don't have pro account so I got error when I was using the command `interpreter`. However, there is another way to use `interpreter` locally and for this aim you shuold install `llama` library on your machine. Also you should download models belonging to `llama` library which help you to run your commands on your machine.**

# Install open-interpreter on Mac
For more information check [this](https://github.com/KillianLucas/open-interpreter/blob/main/docs/MACOS.md) link and [this](https://www.youtube.com/watch?v=SqnXUHwIa3c) youtube video.
